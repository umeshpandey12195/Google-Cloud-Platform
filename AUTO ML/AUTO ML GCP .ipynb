{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import sys\n",
    "\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import automl_v1\n",
    "from google.cloud.automl_v1.proto import service_pb2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Credential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"my-project-12195-46fed19566f2.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Single label classification classifies documents by assigning a label to them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>items</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>bonding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I meditated last night.</td>\n",
       "      <td>leisure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My grandmother start to walk from the bed afte...</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I picked my daughter up from the airport and w...</td>\n",
       "      <td>bonding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when i received flowers from my best friend</td>\n",
       "      <td>bonding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               items      label\n",
       "0  We had a serious talk with some friends of our...    bonding\n",
       "1                            I meditated last night.    leisure\n",
       "2  My grandmother start to walk from the bed afte...  affection\n",
       "3  I picked my daughter up from the airport and w...    bonding\n",
       "4        when i received flowers from my best friend    bonding"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happiness = pd.read_csv('happiness.csv',header=None,names=['items','label'])\n",
    "happiness.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12664 entries, 0 to 12663\n",
      "Data columns (total 2 columns):\n",
      "items    12664 non-null object\n",
      "label    12664 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 198.0+ KB\n"
     ]
    }
   ],
   "source": [
    "happiness.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are total 12664 values in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lets find the distinct classes for label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bonding', 'leisure', 'affection', 'enjoy_the_moment',\n",
       "       'achievement', 'nature', 'exercise'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happiness.label.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are total 7 classes for label column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step to train the model\n",
    "1-The whole model is trained in Google cloud platform\n",
    "\n",
    "2-Open the AutoML Natural Language UI and select Get started in the box corresponding to the type of model you plan to train.\n",
    "\n",
    "3-Click the New Dataset button in the title bar.\n",
    "\n",
    "4-Enter a name for the dataset and select the model as single label classification that matches the sample dataset you choose.\n",
    "\n",
    "6-Leave the Location set to Global.\n",
    "\n",
    "7-In the Import text items section, choose Select a CSV file on Cloud Storage, and enter the path to the dataset you want to use into the text box.\n",
    "\n",
    "8-Now import will take some time and once done we will get a notification\n",
    "\n",
    "9-Now review the dataset .The dataset is splitted it 80 10 10 and we can change it .\n",
    "\n",
    "10-When we are done reviewing the dataset, click the Train tab just below the title bar and Click Start Training.\n",
    "\n",
    "11-Enter a name for the new model and check the Deploy model after training finishes check box.\n",
    "\n",
    "12-Once the model is trained Evaluate the model .Change the thresold as per your requiremnet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now Lets make the prediction on new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "payload {\n",
       "  annotation_spec_id: \"4152891701993668608\"\n",
       "  classification {\n",
       "    score: 0.7859312295913696\n",
       "  }\n",
       "  display_name: \"nature\"\n",
       "}\n",
       "payload {\n",
       "  annotation_spec_id: \"6458734711207362560\"\n",
       "  classification {\n",
       "    score: 0.09789568930864334\n",
       "  }\n",
       "  display_name: \"achievement\"\n",
       "}\n",
       "payload {\n",
       "  annotation_spec_id: \"2711739821235109888\"\n",
       "  classification {\n",
       "    score: 0.0628107562661171\n",
       "  }\n",
       "  display_name: \"enjoy_the_moment\"\n",
       "}\n",
       "payload {\n",
       "  annotation_spec_id: \"5017582830448803840\"\n",
       "  classification {\n",
       "    score: 0.03903582692146301\n",
       "  }\n",
       "  display_name: \"exercise\"\n",
       "}\n",
       "payload {\n",
       "  annotation_spec_id: \"7323425839662497792\"\n",
       "  classification {\n",
       "    score: 0.012882535345852375\n",
       "  }\n",
       "  display_name: \"leisure\"\n",
       "}\n",
       "payload {\n",
       "  annotation_spec_id: \"8764577720421056512\"\n",
       "  classification {\n",
       "    score: 0.0009245725232176483\n",
       "  }\n",
       "  display_name: \"bonding\"\n",
       "}\n",
       "payload {\n",
       "  annotation_spec_id: \"405896812021415936\"\n",
       "  classification {\n",
       "    score: 0.0005194258992560208\n",
       "  }\n",
       "  display_name: \"affection\"\n",
       "}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inline_text_payload(file_path):\n",
    "    with open(file_path, 'rb') as ff:\n",
    "        content = ff.read()\n",
    "    return {'text_snippet': {'content': content, 'mime_type': 'text/plain'} }\n",
    "\n",
    "def pdf_payload(file_path):\n",
    "    return {'document': {'input_config': {'gcs_source': {'input_uris': [file_path] } } } }\n",
    "\n",
    "def get_prediction(file_path, model_name):\n",
    "    options = ClientOptions(api_endpoint='automl.googleapis.com')\n",
    "    prediction_client = automl_v1.PredictionServiceClient(client_options=options)\n",
    "\n",
    "    payload = inline_text_payload(file_path)\n",
    "    # Uncomment the following line (and comment the above line) if want to predict on PDFs.\n",
    "    # payload = pdf_payload(file_path)\n",
    "\n",
    "    params = {}\n",
    "    request = prediction_client.predict(model_name, payload, params)\n",
    "    return request  # waits until request is returned\n",
    "\n",
    "get_prediction('item.txt', 'projects/my-project-12195/locations/us-central1/models/TCN8667988922455818240')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:\n",
    "The text \"I picked up running again now that the winter weather has finally died down. I feel much better physically and emotionally because of it.\" belongs to :\n",
    "\n",
    "    nature class with confidence score of 0.7859312295913696\n",
    "    achievement class with confidence score of 0.09789568930864334\n",
    "    enjoy_the_moment class with confidence score of 0.0628107562661171\n",
    "    exercise class with confidence score of 0.03903582692146301\n",
    "    leisure class with confidence score of 0.012882535345852375\n",
    "    bonding class with confidence score of 0.0009245725232176483\n",
    "    affection class with confidence score of 0.0005194258992560208\n",
    "\n",
    "**Thus the text belongs to nature class**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Prediction on custom Sentiment analysis model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Below Dataset is used to train the sentiment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>content</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>@freewrytin God is way too good for Claritin</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>I need Claritin. So bad. When did I become cur...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>Thank god for Claritin.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>And what's worse is that I reached my 3-day li...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>Time to take some Claritin or Allegra or somet...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split                                            content  Score\n",
       "0  TRAIN       @freewrytin God is way too good for Claritin      2\n",
       "1  TRAIN  I need Claritin. So bad. When did I become cur...      3\n",
       "2  TRAIN                            Thank god for Claritin.      4\n",
       "3  TRAIN  And what's worse is that I reached my 3-day li...      2\n",
       "4  TRAIN  Time to take some Claritin or Allegra or somet...      3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentiment = pd.read_csv('crowdflower-twitter-claritin-80-10-10.csv',header=None,names=['split','content','Score'])\n",
    "Sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4574 entries, 0 to 4573\n",
      "Data columns (total 3 columns):\n",
      "split      4574 non-null object\n",
      "content    4574 non-null object\n",
      "Score      4574 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 107.3+ KB\n"
     ]
    }
   ],
   "source": [
    "Sentiment.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lets find the no of distinct Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentiment.Score.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Same step as above is followed but instead of entity extraction sentiment analysis model is used with maximum score as 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now Lets make the prediction on new sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call the function and pass the txt and sentimental model path to predict the sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "payload {\n",
       "  text_sentiment {\n",
       "    sentiment: 1\n",
       "  }\n",
       "}\n",
       "metadata {\n",
       "  key: \"sentiment_score\"\n",
       "  value: \"-0.4350065\"\n",
       "}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction('sentiment1.txt','projects/my-project-12195/locations/us-central1/models/TST7841015440879910912')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sentiment Score for the text \"I picked the perfect day to forget to take claritin\" is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Prediction on custom Entity extraction mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create an entity extraction model, use a corpus of biomedical research abstracts that mention hundreds of diseases and concepts. The resulting model identifies these medical entities in other documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the function and pass the txt and entity extraction model path to extract the entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "payload {\n",
       "  annotation_spec_id: \"6712906615177084928\"\n",
       "  display_name: \"SpecificDisease\"\n",
       "  text_extraction {\n",
       "    score: 0.9993165135383606\n",
       "    text_segment {\n",
       "      start_offset: 36\n",
       "      end_offset: 43\n",
       "      content: \"obesity\"\n",
       "    }\n",
       "  }\n",
       "}\n",
       "payload {\n",
       "  annotation_spec_id: \"227723151763570688\"\n",
       "  display_name: \"Modifier\"\n",
       "  text_extraction {\n",
       "    score: 0.9985511898994446\n",
       "    text_segment {\n",
       "      start_offset: 394\n",
       "      end_offset: 412\n",
       "      content: \"mesenchymal tumour\"\n",
       "    }\n",
       "  }\n",
       "}\n",
       "payload {\n",
       "  annotation_spec_id: \"9018749624390778880\"\n",
       "  display_name: \"DiseaseClass\"\n",
       "  text_extraction {\n",
       "    score: 0.9135051369667053\n",
       "    text_segment {\n",
       "      start_offset: 436\n",
       "      end_offset: 452\n",
       "      content: \"fat-cell tumours\"\n",
       "    }\n",
       "  }\n",
       "}\n",
       "payload {\n",
       "  annotation_spec_id: \"9018749624390778880\"\n",
       "  display_name: \"DiseaseClass\"\n",
       "  text_extraction {\n",
       "    score: 0.9969135522842407\n",
       "    text_segment {\n",
       "      start_offset: 455\n",
       "      end_offset: 462\n",
       "      content: \"lipomas\"\n",
       "    }\n",
       "  }\n",
       "}\n",
       "payload {\n",
       "  annotation_spec_id: \"6712906615177084928\"\n",
       "  display_name: \"SpecificDisease\"\n",
       "  text_extraction {\n",
       "    score: 0.9991968274116516\n",
       "    text_segment {\n",
       "      start_offset: 567\n",
       "      end_offset: 574\n",
       "      content: \"obesity\"\n",
       "    }\n",
       "  }\n",
       "}\n",
       "payload {\n",
       "  annotation_spec_id: \"227723151763570688\"\n",
       "  display_name: \"Modifier\"\n",
       "  text_extraction {\n",
       "    score: 0.9989087581634521\n",
       "    text_segment {\n",
       "      start_offset: 639\n",
       "      end_offset: 644\n",
       "      content: \"obese\"\n",
       "    }\n",
       "  }\n",
       "}\n",
       "payload {\n",
       "  annotation_spec_id: \"4407063605963390976\"\n",
       "  display_name: \"CompositeMention\"\n",
       "  text_extraction {\n",
       "    score: 0.9976733326911926\n",
       "    text_segment {\n",
       "      start_offset: 664\n",
       "      end_offset: 703\n",
       "      content: \"partial or complete deficiency of Hmgic\"\n",
       "    }\n",
       "  }\n",
       "}\n",
       "payload {\n",
       "  annotation_spec_id: \"6712906615177084928\"\n",
       "  display_name: \"SpecificDisease\"\n",
       "  text_extraction {\n",
       "    score: 0.9993381500244141\n",
       "    text_segment {\n",
       "      start_offset: 726\n",
       "      end_offset: 733\n",
       "      content: \"obesity\"\n",
       "    }\n",
       "  }\n",
       "}\n",
       "payload {\n",
       "  annotation_spec_id: \"6712906615177084928\"\n",
       "  display_name: \"SpecificDisease\"\n",
       "  text_extraction {\n",
       "    score: 0.9993481040000916\n",
       "    text_segment {\n",
       "      start_offset: 782\n",
       "      end_offset: 789\n",
       "      content: \"obesity\"\n",
       "    }\n",
       "  }\n",
       "}\n",
       "payload {\n",
       "  annotation_spec_id: \"6712906615177084928\"\n",
       "  display_name: \"SpecificDisease\"\n",
       "  text_extraction {\n",
       "    score: 0.9995229244232178\n",
       "    text_segment {\n",
       "      start_offset: 801\n",
       "      end_offset: 818\n",
       "      content: \"leptin deficiency\"\n",
       "    }\n",
       "  }\n",
       "}\n",
       "payload {\n",
       "  annotation_spec_id: \"6712906615177084928\"\n",
       "  display_name: \"SpecificDisease\"\n",
       "  text_extraction {\n",
       "    score: 0.999294102191925\n",
       "    text_segment {\n",
       "      start_offset: 1012\n",
       "      end_offset: 1019\n",
       "      content: \"obesity\"\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction('entity2.txt','projects/my-project-12195/locations/us-central1/models/TEN7001657060328734720')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result**\n",
    "\n",
    "In the above output\n",
    "\n",
    "\"Obesity\" belongs to Class \"SpecificDisease\" with score 0.9993165135383606\n",
    "\n",
    "\"mesenchymal tumour\" belongs to class \"Modifier\" with score 0.9985511898994446\n",
    "\n",
    "\"fat-cell tumours\" belongs to class \"DiseaseClass\" with score of 0.9135051369667053\n",
    "\n",
    "\"lipomas\" belongs to class \"DiseaseClass\" with score of 0.9969135522842407\n",
    "\n",
    "\"obese\" belongs to class \"Modifier\" with score of 0.9989087581634521\n",
    "\n",
    "\"partial or complete deficiency of Hmgic\" belongs to \"CompositeMention\" with score of 0.9989087581634521\n",
    "\n",
    "\"leptin deficiency\" belongs to class \"SpecificDisease\" with score of 0.9995229244232178\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
